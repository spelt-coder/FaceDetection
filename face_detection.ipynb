{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd4ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV with Haar Cascade\n",
    "import cv2\n",
    "\n",
    "def detect_faces(image, cascade):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # Draw rectangles around detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def main():\n",
    "    # Load the cascade for face detection\n",
    "    face_cascade = cv2.CascadeClassifier('opencv_haarcascade/haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread('imgs/prebbieGroup1.png')\n",
    "\n",
    "    # Check if the image is successfully loaded\n",
    "    if image is None:\n",
    "        print(\"Error: Unable to open the image.\")\n",
    "        return\n",
    "\n",
    "    # Detect faces and display the result\n",
    "    result_image = detect_faces(image, face_cascade)\n",
    "    cv2.imshow('Face Detection', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e4210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV with DNN\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the DNN Face Detector model\n",
    "face_detector = cv2.dnn.readNetFromCaffe(\"opencv_dnn/deploy.prototxt\", \"opencv_dnn/res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "\n",
    "# Read the input image\n",
    "print(\"Read the input image\")\n",
    "image = cv2.imread(\"imgs/faces.jpg\")\n",
    "\n",
    "# Get the height and width of the input image\n",
    "(h, w) = image.shape[:2]\n",
    "\n",
    "# Preprocess the image by resizing it and converting it to a blob\n",
    "print(\"Preprocessing the image\")\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "# Feed the blob as input to the DNN Face Detector model\n",
    "face_detector.setInput(blob)\n",
    "detections = face_detector.forward()\n",
    "\n",
    "# Loop over the detections and draw a rectangle around each face\n",
    "print(\"Iterate over detections and create a rectangle\")\n",
    "for i in range(0, detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "\n",
    "    # Filter out weak detections\n",
    "    if confidence > 0.5:\n",
    "        # Get the bounding box for the face\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "\n",
    "# Show the output image\n",
    "print(\"Show the final output\")\n",
    "cv2.imshow(\"Output\", image) #To run in Google Colab, comment out this line Colab notebook\n",
    "#cv2_imshow(image) #To run in Google Colab, uncomment this line\n",
    "cv2.waitKey(0)\n",
    "print(\"Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402af9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dlib with CNN\n",
    "\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# Load face detection model\n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1(\"dlib_cnn/mmod_human_face_detector.dat\")\n",
    "\n",
    "# Load image\n",
    "image_path = 'imgs/groupPhoto1.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces using CNN model\n",
    "faces = cnn_face_detector(gray, 1)\n",
    "for faceRect in faces:\n",
    "    rect =  faceRect.rect\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() - y\n",
    "    \n",
    "    # Draw rectangle around each face\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dlib with HoG and linear SVM\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image_path = 'imgs/faces.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale (Dlib works with grayscale images)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "faces = detector(gray)\n",
    "\n",
    "for face in faces:\n",
    "    x, y, w, h = (face.left(), face.top(), face.width(), face.height())\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    \n",
    "# Save the output image\n",
    "output_path = \"out/hog_output.jpg\"\n",
    "cv2.imwrite(output_path, image)\n",
    "print(f\"Output image saved to {output_path}\")    \n",
    "\n",
    "# Display the image with OpenCV\n",
    "cv2.imshow(\"Faces Detected\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtcnn\n",
    "import cv2\n",
    "import mtcnn\n",
    "\n",
    "def draw_facebox(filename, result_list):\n",
    "    # load the image using OpenCV\n",
    "    data = cv2.imread(filename)\n",
    "    # convert from BGR to RGB\n",
    "    data_rgb = cv2.cvtColor(data, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # get the context for drawing boxes\n",
    "    for result in result_list:\n",
    "        # get coordinates\n",
    "        x, y, width, height = result['box']\n",
    "        # draw rectangle\n",
    "        cv2.rectangle(data_rgb, (x, y), (x+width, y+height), (0, 255, 0), 2)\n",
    "\n",
    "    # display the image with faces\n",
    "    #cv2.imshow(\"Detected Faces with mtcnn\", cv2.cvtColor(data_rgb, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imshow(\"Detected Faces with mtcnn\", data_rgb)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "filename = \"imgs/footballTeam.png\"  # File location\n",
    "pixels = cv2.imread(filename)  # defined above, otherwise uncomment\n",
    "# detector is defined above, otherwise uncomment\n",
    "detector = mtcnn.MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "# display faces on the original image\n",
    "draw_facebox(filename, faces)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
